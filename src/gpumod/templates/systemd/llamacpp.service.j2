[Unit]
Description={{ service.name }}
After=network.target

[Service]
Type=simple
User={{ settings.user | default('root') }}
Environment="CUDA_VISIBLE_DEVICES={{ settings.cuda_devices | default('0') }}"
{% for key, value in extra_env.items() %}
Environment="{{ key }}={{ value }}"
{% endfor %}

ExecStart={{ settings.llamacpp_bin | default('llama-server') }} \
    --model {{ unit_vars.model_path }} \
    --port {{ service.port }} \
    --host 0.0.0.0 \
    --ctx-size {{ unit_vars.context_size | default(4096) }} \
    --n-gpu-layers {{ unit_vars.n_gpu_layers | default(-1) }}{% if unit_vars.flash_attn | default(false) %} \
    --flash-attn{% endif %}{% if unit_vars.preset_file is defined %} \
    --override-kv {{ unit_vars.preset_file }}{% endif %}{% if unit_vars.extra_args is defined %} \
    {{ unit_vars.extra_args }}{% endif %}

Restart=on-failure
RestartSec=30

[Install]
WantedBy=multi-user.target
