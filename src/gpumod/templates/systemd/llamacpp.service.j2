[Unit]
Description={{ service.name }}
After=network.target

[Service]
Type=simple
Environment="CUDA_VISIBLE_DEVICES={{ settings.cuda_devices | default('0') }}"
{% for key, value in extra_env.items() %}
Environment="{{ key }}={{ value }}"
{% endfor %}

ExecStart={{ settings.llamacpp_bin | default('llama-server') }} \
{%- if unit_vars.models_dir is defined %}
    --models-dir {{ unit_vars.models_dir }} \
{%- if unit_vars.no_models_autoload | default(false) %}
    --no-models-autoload \
{%- endif %}
{%- if unit_vars.models_max is defined %}
    --models-max {{ unit_vars.models_max }} \
{%- endif %}
{%- else %}
    --model {{ unit_vars.model_path }} \
{%- endif %}
    --port {{ service.port }} \
    --host 0.0.0.0 \
{%- if unit_vars.context_size is defined or unit_vars.models_dir is not defined %}
    --ctx-size {{ unit_vars.context_size | default(4096) }} \
{%- endif %}
    --n-gpu-layers {{ unit_vars.n_gpu_layers | default(-1) }}
{%- if unit_vars.jinja | default(false) %} \
    --jinja
{%- endif %}
{%- if unit_vars.flash_attn | default(false) %} \
    --flash-attn
{%- endif %}
{%- if unit_vars.preset_file is defined %} \
    --override-kv {{ unit_vars.preset_file }}
{%- endif %}
{%- if unit_vars.extra_args is defined %} \
    {{ unit_vars.extra_args }}
{%- endif %}

Restart=on-failure
RestartSec=30

[Install]
WantedBy=default.target
