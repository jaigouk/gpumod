{"id":"gpumod-033","title":"Phase 3: CLI \u0026 Visualization","description":"Typer-based CLI (gpumod init, service/mode/template commands), Rich ASCII VRAM visualization, status dashboard, unit generation and installation.","status":"open","priority":2,"issue_type":"feature","owner":"ping@jaigouk.kim","created_at":"2026-02-06T21:36:18.404397706+01:00","created_by":"Jaigouk Kim","updated_at":"2026-02-06T21:36:18.404397706+01:00","dependencies":[{"issue_id":"gpumod-033","depends_on_id":"gpumod-3cw","type":"blocks","created_at":"2026-02-06T21:36:29.154591848+01:00","created_by":"Jaigouk Kim"}]}
{"id":"gpumod-0gc","title":"ARCHITECT: Design Phase 1 architecture and create ARCHITECTURE.md","description":"## Goal\nDesign the Phase 1 services layer architecture and document it in docs/ARCHITECTURE.md. This is the source of truth that all DEVELOPER tickets must respect.\n\n## Problem\nDevelopers need a single authoritative reference for module boundaries, interfaces, dependency flow, and design decisions. Without this, implementations will diverge and refactoring will be expensive.\n\n## Role: ARCHITECT\nThe ARCHITECT owns docs/ARCHITECTURE.md and must:\n- Create the initial architecture document before any implementation begins\n- Update it when design decisions change (with rationale)\n- Review DEVELOPER work for architecture compliance\n- Respond to DEVELOPER questions about design\n\n## Steps\n\n### 1. Create docs/ARCHITECTURE.md with these sections:\n\n#### Overview\n- What gpumod does (1 paragraph)\n- Target platform: Linux, single NVIDIA GPU, systemd\n- Python 3.11+, async-first design\n\n#### Module Map\n```\nsrc/gpumod/\n├── __init__.py              # Package root, __version__\n├── models.py                # All Pydantic models and enums (NO business logic)\n├── db.py                    # SQLite async database layer\n└── services/\n    ├── __init__.py           # Public API re-exports\n    ├── base.py               # ServiceDriver ABC\n    ├── systemd.py            # async systemctl wrapper\n    ├── registry.py           # Service ↔ Driver mapping\n    ├── lifecycle.py          # Dependency-ordered start/stop\n    ├── vram.py               # nvidia-smi VRAM tracking\n    ├── sleep.py              # Sleep/wake controller\n    ├── manager.py            # Top-level orchestrator\n    └── drivers/\n        ├── __init__.py\n        ├── vllm.py           # vLLM driver (systemd + HTTP)\n        ├── llamacpp.py       # llama.cpp driver (router mode)\n        └── fastapi.py        # Generic FastAPI driver\n```\n\n#### Dependency Graph (module-level)\n```\nmodels.py (no deps - leaf module)\n    ↑\ndb.py (depends on: models)\n    ↑\nservices/base.py (depends on: models)\nservices/systemd.py (no internal deps - OS interface)\n    ↑\nservices/drivers/* (depends on: base, models, systemd)\n    ↑\nservices/registry.py (depends on: db, models, base, drivers/*)\n    ↑\nservices/lifecycle.py (depends on: registry, models)\nservices/vram.py (depends on: models)\nservices/sleep.py (depends on: registry, models)\n    ↑\nservices/manager.py (depends on: db, registry, lifecycle, vram, sleep, models)\n```\n\n#### Design Principles\n1. **Async-first**: All I/O operations are async (aiosqlite, httpx, subprocess)\n2. **Dependency injection**: Components receive dependencies via constructor, not global state\n3. **Models are dumb**: Pydantic models carry data only - no business logic in models.py\n4. **Drivers are thin**: Drivers wrap external APIs (systemd, HTTP), orchestration lives in manager/lifecycle\n5. **Errors are typed**: Each module defines its own exception class (SystemdError, NvidiaSmiError, etc.)\n6. **No hardcoded paths**: All paths come from DB settings or environment variables\n7. **Testable by default**: All external dependencies (systemd, nvidia-smi, HTTP) are mockable\n\n#### Interface Contracts\nDocument the key interfaces:\n- ServiceDriver ABC: what each method must do, what it can assume, what it must not do\n- Database: thread safety guarantees, connection lifecycle\n- systemd module: security constraints (input validation, command allowlist)\n\n#### Error Handling Strategy\n- Drivers: never raise from status() or health_check() - return error states\n- Lifecycle: raise LifecycleError with context (service_id, operation, reason)\n- VRAMTracker: raise NvidiaSmiError when GPU tools unavailable\n- ServiceManager: catch and wrap errors in ModeResult for callers\n\n#### Security Considerations\n- systemd.py: validate unit names against injection (no shell metacharacters)\n- systemd.py: command allowlist (only known systemctl subcommands)\n- HTTP clients: use timeouts on all requests\n- No secrets in DB (API keys, tokens) - use environment variables\n- No eval() or exec() anywhere\n\n#### Performance Considerations\n- Use asyncio.gather for concurrent status checks (not sequential)\n- HTTP connection pooling where appropriate\n- nvidia-smi calls are expensive (~100ms) - cache when appropriate\n- SQLite WAL mode for concurrent read/write\n\n### 2. Review against plan.md (the plan won't be committed but use it as reference now)\n- Ensure ARCHITECTURE.md captures all plan.md design decisions relevant to Phase 1\n- Flag any plan.md designs that need modification\n\n### 3. Create a DECISIONS.md (optional, in docs/)\nLog key architecture decisions with rationale:\n- ADR-001: Why async-first (not sync)\n- ADR-002: Why SQLite (not JSON/YAML config files)\n- ADR-003: Why Pydantic v2 (not dataclasses)\n\n## Acceptance Criteria\n- [ ] docs/ARCHITECTURE.md exists with all sections above\n- [ ] Module map matches planned src/gpumod/ structure\n- [ ] Dependency graph is acyclic and documented\n- [ ] Interface contracts for ServiceDriver ABC are specified\n- [ ] Security considerations documented\n- [ ] Error handling strategy documented\n- [ ] All DEVELOPER tickets can be implemented using only ARCHITECTURE.md as reference\n- [ ] No references to plan.md in ARCHITECTURE.md (self-contained)","status":"closed","priority":1,"issue_type":"task","owner":"ping@jaigouk.kim","created_at":"2026-02-06T21:44:01.265337204+01:00","created_by":"Jaigouk Kim","updated_at":"2026-02-06T22:03:43.213387351+01:00","closed_at":"2026-02-06T22:03:43.213387351+01:00","close_reason":"Created comprehensive ARCHITECTURE.md covering all system layers, service abstraction, configuration layer, simulation engine, and design decisions","dependencies":[{"issue_id":"gpumod-0gc","depends_on_id":"gpumod-lti","type":"blocks","created_at":"2026-02-06T21:44:08.444993884+01:00","created_by":"Jaigouk Kim"}]}
{"id":"gpumod-1nb","title":"Phase 4: Simulation \u0026 MCP Server","description":"Pre-simulation engine (VRAM fitting), gpumod simulate command, FastMCP server with DB-backed tools, MCP resources for browsing services/modes, integration tests.","status":"open","priority":2,"issue_type":"feature","owner":"ping@jaigouk.kim","created_at":"2026-02-06T21:36:19.989969271+01:00","created_by":"Jaigouk Kim","updated_at":"2026-02-06T21:36:19.989969271+01:00","dependencies":[{"issue_id":"gpumod-1nb","depends_on_id":"gpumod-033","type":"blocks","created_at":"2026-02-06T21:36:29.183785756+01:00","created_by":"Jaigouk Kim"}]}
{"id":"gpumod-2kc","title":"Implement systemd helper (systemctl wrapper)","description":"## Goal\nCreate an async wrapper around systemctl for managing systemd units. This is the OS-level interface that all systemd-based drivers depend on.\n\n## Problem\nAll service drivers (vLLM, llama.cpp, FastAPI) manage services via systemd. We need a clean async interface for systemctl that handles output parsing, error codes, and permission issues consistently.\n\n## Architecture Reference\nRead docs/ARCHITECTURE.md before starting. Key principles:\n- systemd.py is the OS interface layer (no internal deps except models)\n- Security: validate unit names, command allowlist\n- All operations async via create_subprocess_exec\n- If you have a design question, update the ticket notes and tag ARCHITECT\n\n## Workflow: Red → Green → Refactor\n\n### RED: Write failing tests first\nCreate `tests/unit/test_systemd.py`:\n- Mock `asyncio.create_subprocess_exec` for all tests\n- Test successful start/stop/restart return without error\n- Test is_active returns True for \"active\" units\n- Test is_active returns False for \"inactive\" or failed subprocess\n- Test is_active never raises (returns False on any error)\n- Test get_unit_state parses \"active\", \"inactive\", \"failed\" etc.\n- Test SystemdError contains command name and stderr in message\n- Test timeout raises asyncio.TimeoutError\n- Test unit name validation: reject names containing `;`, `|`, `$`, `` ` ``, `\u0026`, `(`, `)`, `{`, `}`\n- Test unit name validation: accept valid names like \"vllm-embedding.service\"\n- Test command validation: reject unknown commands (e.g., \"daemon-reload\")\n- Test command validation: accept allowlisted commands (start, stop, restart, is-active, status, enable, disable, show)\n\nRun tests - they must ALL FAIL:\n```bash\nuv run pytest tests/unit/test_systemd.py -v\n# Expected: ALL FAIL\n```\n\n### GREEN: Minimal implementation\nCreate `src/gpumod/services/systemd.py`:\n\n```python\nimport asyncio\nimport re\nfrom dataclasses import dataclass\n\nALLOWED_COMMANDS = frozenset({\"start\", \"stop\", \"restart\", \"is-active\", \"status\", \"enable\", \"disable\", \"show\"})\nUNIT_NAME_PATTERN = re.compile(r\"^[a-zA-Z0-9_@:.-]+$\")\n\n@dataclass\nclass SystemctlResult:\n    return_code: int\n    stdout: str\n    stderr: str\n\n    @property\n    def success(self) -\u003e bool:\n        return self.return_code == 0\n\nclass SystemdError(Exception):\n    def __init__(self, command: str, result: SystemctlResult) -\u003e None:\n        self.command = command\n        self.result = result\n        super().__init__(f\"systemctl {command} failed (rc={result.return_code}): {result.stderr}\")\n\ndef _validate_unit_name(unit: str) -\u003e None:\n    if not UNIT_NAME_PATTERN.match(unit):\n        raise ValueError(f\"Invalid unit name: {unit!r}\")\n\ndef _validate_command(command: str) -\u003e None:\n    if command not in ALLOWED_COMMANDS:\n        raise ValueError(f\"Unknown systemctl command: {command!r}\")\n\nasync def systemctl(command: str, unit: str, *, timeout: float = 30.0) -\u003e SystemctlResult: ...\nasync def is_active(unit: str) -\u003e bool: ...\nasync def is_enabled(unit: str) -\u003e bool: ...\nasync def get_unit_state(unit: str) -\u003e str: ...\nasync def start(unit: str, *, timeout: float = 30.0) -\u003e None: ...\nasync def stop(unit: str, *, timeout: float = 30.0) -\u003e None: ...\nasync def restart(unit: str, *, timeout: float = 30.0) -\u003e None: ...\n```\n\nRun tests - they must ALL PASS:\n```bash\nuv run pytest tests/unit/test_systemd.py -v\n# Expected: ALL PASS\n```\n\n### REFACTOR: Quality, Performance, Security\n1. **Code quality**: Docstrings on all public functions, consistent error messages\n2. **Performance**: Subprocess timeout prevents hanging, no unnecessary parsing\n3. **Security review** (CRITICAL for this module):\n   - Unit name regex rejects ALL shell metacharacters\n   - Command allowlist prevents arbitrary systemctl subcommands\n   - No shell=True anywhere (use exec form only)\n   - No string interpolation into shell commands\n   - Verify the regex pattern catches edge cases (unicode, null bytes, etc.)\n\n## Quality Gate (must pass before closing)\n```bash\nuv run ruff check src/gpumod/services/systemd.py tests/unit/test_systemd.py\nuv run mypy src/gpumod/services/systemd.py --strict\nuv run pytest tests/unit/test_systemd.py -v --cov=src/gpumod/services/systemd --cov-report=term-missing --cov-fail-under=80\n```\nALL THREE must exit 0. Do not close this ticket until they do.\n\n## Acceptance Criteria\n- [ ] RED: All tests written and failing before implementation\n- [ ] GREEN: All tests passing with minimal implementation\n- [ ] REFACTOR: Code reviewed for quality, performance, security\n- [ ] Unit name validation prevents command injection\n- [ ] Command allowlist prevents arbitrary systemctl subcommands\n- [ ] No shell=True in any subprocess call\n- [ ] SystemdError includes the command and stderr\n- [ ] is_active/is_enabled never raise (return False on error)\n- [ ] All functions are async\n- [ ] `ruff check` passes\n- [ ] `mypy --strict` passes\n- [ ] Test coverage \u003e= 80%\n- [ ] Architecture compliant (checked against docs/ARCHITECTURE.md)","status":"open","priority":1,"issue_type":"task","owner":"ping@jaigouk.kim","created_at":"2026-02-06T21:37:09.867754966+01:00","created_by":"Jaigouk Kim","updated_at":"2026-02-06T21:45:36.680961993+01:00","dependencies":[{"issue_id":"gpumod-2kc","depends_on_id":"gpumod-lti","type":"blocks","created_at":"2026-02-06T21:37:24.073880674+01:00","created_by":"Jaigouk Kim"},{"issue_id":"gpumod-2kc","depends_on_id":"gpumod-0gc","type":"blocks","created_at":"2026-02-06T21:44:08.538635066+01:00","created_by":"Jaigouk Kim"}]}
{"id":"gpumod-3cw","title":"Phase 2: Templates \u0026 Model Registry","description":"Jinja2 systemd templates, YAML preset format, template rendering engine, HuggingFace/GGUF model info fetcher, model registry with VRAM estimation.","status":"open","priority":2,"issue_type":"feature","owner":"ping@jaigouk.kim","created_at":"2026-02-06T21:36:16.487826475+01:00","created_by":"Jaigouk Kim","updated_at":"2026-02-06T21:36:16.487826475+01:00","dependencies":[{"issue_id":"gpumod-3cw","depends_on_id":"gpumod-qf3","type":"blocks","created_at":"2026-02-06T21:36:29.125742963+01:00","created_by":"Jaigouk Kim"}]}
{"id":"gpumod-6gy","title":"Implement ServiceManager orchestrator","description":"## Goal\nImplement the ServiceManager - the top-level orchestrator composing all service-layer components.\n\n## Problem\nThe CLI, MCP server, and interactive mode all need: switch mode, get status, start/stop services. The ServiceManager provides a single entry point that coordinates registry, lifecycle, VRAM tracking, and sleep.\n\n## Architecture Reference\nRead docs/ARCHITECTURE.md before starting. Key principles:\n- ServiceManager depends on: db, registry, lifecycle, vram, sleep, models\n- This is the top of the dependency graph - it composes everything\n- Dependency injection: all components passed or created in constructor\n- If you have a design question, update the ticket notes and tag ARCHITECT\n\n## Workflow: Red → Green → Refactor\n\n### RED: Write failing tests first\nCreate `tests/unit/test_manager.py`:\n\nTest setup: Mock Database with 2 modes:\n- \"code\" mode: services [svc-embed, svc-devstral]\n- \"rag\" mode: services [svc-embed, svc-rag-llm, svc-reranker]\n- Shared service: svc-embed (in both modes)\n- Mock all sub-components (registry, lifecycle, vram, sleep)\n\n**Mode switch tests:**\n- Test switch from \"code\" to \"rag\": stops svc-devstral, starts svc-rag-llm + svc-reranker, keeps svc-embed\n- Test switch returns ModeResult(success=True) with correct started/stopped lists\n- Test switch to unknown mode returns ModeResult(success=False, error=\"Mode not found: ...\")\n- Test switch when VRAM would exceed returns ModeResult(success=False, error=\"Would exceed VRAM by Xmb\")\n- Test switch from None (no current mode) starts all target services\n- Test switch stops services BEFORE starting new ones (free VRAM first)\n- Test switch updates current_mode in DB after successful switch\n- Test switch does NOT update current_mode on failure\n\n**Status tests:**\n- Test get_status() includes all services with their statuses\n- Test get_status() calculates vram_used_mb from sum of status.vram_mb\n- Test get_status() includes GPU info from VRAMTracker\n- Test get_status() works gracefully when nvidia-smi fails (gpu=None)\n- Test get_status() gathers statuses concurrently (verify asyncio.gather used)\n\n**Convenience tests:**\n- Test start_service delegates to lifecycle.start\n- Test stop_service delegates to lifecycle.stop\n\nRun tests - they must ALL FAIL:\n```bash\nuv run pytest tests/unit/test_manager.py -v\n```\n\n### GREEN: Minimal implementation\nCreate `src/gpumod/services/manager.py` with ServiceManager class.\n\nRun tests - they must ALL PASS.\n\n### REFACTOR: Quality, Performance, Security\n1. **Code quality**: Clean composition, docstrings, separation of concerns\n2. **Performance**:\n   - get_status() uses asyncio.gather for concurrent status checks\n   - switch_mode() stops before starting (sequential, to free VRAM)\n   - VRAM pre-flight is best-effort (don't fail if nvidia-smi unavailable)\n3. **Security**:\n   - Mode names validated (prevent injection through mode lookup)\n   - No sensitive data in ModeResult error messages\n\n## Quality Gate (must pass before closing)\n```bash\nuv run ruff check src/gpumod/services/manager.py tests/unit/test_manager.py\nuv run mypy src/gpumod/services/manager.py --strict\nuv run pytest tests/unit/test_manager.py -v --cov=src/gpumod/services/manager --cov-report=term-missing --cov-fail-under=80\n```\nALL THREE must exit 0. Do not close this ticket until they do.\n\n## Acceptance Criteria\n- [ ] RED: All tests written and failing before implementation\n- [ ] GREEN: All tests passing with minimal implementation\n- [ ] REFACTOR: Code reviewed for quality, performance, security\n- [ ] switch_mode() calculates correct service diff\n- [ ] switch_mode() does VRAM pre-flight check\n- [ ] switch_mode() stops before starting (free VRAM first)\n- [ ] switch_mode() returns descriptive ModeResult\n- [ ] get_status() gathers statuses concurrently\n- [ ] get_status() handles nvidia-smi failure gracefully\n- [ ] ServiceManager composes all sub-components\n- [ ] `ruff check` passes\n- [ ] `mypy --strict` passes\n- [ ] Test coverage \u003e= 80%\n- [ ] Architecture compliant (checked against docs/ARCHITECTURE.md)","status":"open","priority":1,"issue_type":"task","owner":"ping@jaigouk.kim","created_at":"2026-02-06T21:37:07.287397134+01:00","created_by":"Jaigouk Kim","updated_at":"2026-02-06T21:48:15.79271623+01:00","dependencies":[{"issue_id":"gpumod-6gy","depends_on_id":"gpumod-7dp","type":"blocks","created_at":"2026-02-06T21:37:24.575999142+01:00","created_by":"Jaigouk Kim"},{"issue_id":"gpumod-6gy","depends_on_id":"gpumod-7p3","type":"blocks","created_at":"2026-02-06T21:37:24.605087632+01:00","created_by":"Jaigouk Kim"},{"issue_id":"gpumod-6gy","depends_on_id":"gpumod-zl5","type":"blocks","created_at":"2026-02-06T21:37:24.635535404+01:00","created_by":"Jaigouk Kim"},{"issue_id":"gpumod-6gy","depends_on_id":"gpumod-8ac","type":"blocks","created_at":"2026-02-06T21:37:24.665285795+01:00","created_by":"Jaigouk Kim"}]}
{"id":"gpumod-71s","title":"Implement SQLite schema and db.py","description":"## Goal\nCreate the SQLite database layer for gpumod. This stores all configuration: services, modes, GPU profiles, and settings.\n\n## Problem\nThe current approach hardcodes all config in Python. gpumod needs persistent, user-editable configuration in SQLite so users can add services/modes without editing code.\n\n## Architecture Reference\nRead docs/ARCHITECTURE.md before starting. Key principles:\n- Database depends only on models.py\n- Async via aiosqlite\n- Dependency injection: Database instance passed to components\n- If you have a design question, update the ticket notes and tag ARCHITECT\n\n## Workflow: Red → Green → Refactor\n\n### RED: Write failing tests first\nCreate `tests/unit/test_db.py`:\n- Use tmp_path fixture for isolated test databases\n- Test connect() creates all tables (check sqlite_master)\n- Test connect() sets schema_version\n- Test re-connect on existing DB doesn't recreate tables or lose data\n- Test insert_service + get_service round-trip with Service model\n- Test list_services returns all services ordered by ID\n- Test get_service returns None for unknown ID\n- Test delete_service removes service\n- Test insert_mode + get_mode round-trip\n- Test get_mode_services returns services in start_order\n- Test set_mode_services creates junction records\n- Test get/set_setting round-trip\n- Test get_setting returns default for missing key\n- Test get/set_current_mode\n- Test async context manager (async with Database(...) as db)\n- Test foreign key cascade: deleting a mode removes mode_services entries\n\nRun tests - they must ALL FAIL:\n```bash\nuv run pytest tests/unit/test_db.py -v\n# Expected: ALL FAIL\n```\n\n### GREEN: Minimal implementation\nCreate `src/gpumod/db.py`:\n\n```python\nimport aiosqlite\nfrom pathlib import Path\nfrom gpumod.models import Service, Mode, DriverType, SleepMode\n\nSCHEMA_V1 = \"\"\"\nCREATE TABLE IF NOT EXISTS schema_version (\n    version INTEGER PRIMARY KEY,\n    applied_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n);\nCREATE TABLE IF NOT EXISTS gpu_profiles (\n    id TEXT PRIMARY KEY, name TEXT NOT NULL, vram_mb INTEGER NOT NULL,\n    architecture TEXT, created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n);\nCREATE TABLE IF NOT EXISTS services (\n    id TEXT PRIMARY KEY, name TEXT NOT NULL, driver TEXT NOT NULL,\n    port INTEGER, vram_mb INTEGER NOT NULL,\n    sleep_mode TEXT DEFAULT 'none', health_endpoint TEXT DEFAULT '/health',\n    model_id TEXT, unit_name TEXT, depends_on JSON DEFAULT '[]',\n    startup_timeout INTEGER DEFAULT 120, extra_config JSON DEFAULT '{}',\n    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n);\nCREATE TABLE IF NOT EXISTS modes (\n    id TEXT PRIMARY KEY, name TEXT NOT NULL, description TEXT DEFAULT '',\n    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n);\nCREATE TABLE IF NOT EXISTS mode_services (\n    mode_id TEXT REFERENCES modes(id) ON DELETE CASCADE,\n    service_id TEXT REFERENCES services(id) ON DELETE CASCADE,\n    start_order INTEGER DEFAULT 0, sleep_on_idle BOOLEAN DEFAULT FALSE,\n    PRIMARY KEY (mode_id, service_id)\n);\nCREATE TABLE IF NOT EXISTS settings (\n    key TEXT PRIMARY KEY, value TEXT NOT NULL, description TEXT,\n    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n);\nCREATE TABLE IF NOT EXISTS current_state (\n    key TEXT PRIMARY KEY, value TEXT NOT NULL,\n    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n);\n\"\"\"\n\nclass Database:\n    def __init__(self, db_path: Path) -\u003e None: ...\n    async def connect(self) -\u003e None: ...\n    async def close(self) -\u003e None: ...\n    async def __aenter__(self) -\u003e \"Database\": ...\n    async def __aexit__(self, *args: object) -\u003e None: ...\n\n    # Services CRUD\n    async def list_services(self) -\u003e list[Service]: ...\n    async def get_service(self, service_id: str) -\u003e Service | None: ...\n    async def insert_service(self, service: Service) -\u003e None: ...\n    async def delete_service(self, service_id: str) -\u003e None: ...\n\n    # Modes CRUD\n    async def list_modes(self) -\u003e list[Mode]: ...\n    async def get_mode(self, mode_id: str) -\u003e Mode | None: ...\n    async def insert_mode(self, mode: Mode) -\u003e None: ...\n    async def get_mode_services(self, mode_id: str) -\u003e list[Service]: ...\n    async def set_mode_services(self, mode_id: str, service_ids: list[str], orders: list[int] | None = None) -\u003e None: ...\n\n    # Settings\n    async def get_setting(self, key: str, default: str | None = None) -\u003e str | None: ...\n    async def set_setting(self, key: str, value: str, description: str = \"\") -\u003e None: ...\n\n    # State\n    async def get_current_mode(self) -\u003e str | None: ...\n    async def set_current_mode(self, mode_id: str) -\u003e None: ...\n```\n\nRun tests - they must ALL PASS:\n```bash\nuv run pytest tests/unit/test_db.py -v\n# Expected: ALL PASS\n```\n\n### REFACTOR: Quality, Performance, Security\n1. **Code quality**: Consistent SQL formatting, docstrings, error messages\n2. **Performance**: Enable WAL mode for concurrent reads, use parameterized queries\n3. **Security**:\n   - ALL queries use parameterized statements (? placeholders), NEVER string formatting\n   - No SQL injection vectors\n   - Foreign keys enforced (PRAGMA foreign_keys = ON)\n   - JSON fields properly serialized/deserialized (json.dumps/loads)\n\n## Quality Gate (must pass before closing)\n```bash\nuv run ruff check src/gpumod/db.py tests/unit/test_db.py\nuv run mypy src/gpumod/db.py --strict\nuv run pytest tests/unit/test_db.py -v --cov=src/gpumod/db --cov-report=term-missing --cov-fail-under=80\n```\nALL THREE must exit 0. Do not close this ticket until they do.\n\n## Acceptance Criteria\n- [ ] RED: All tests written and failing before implementation\n- [ ] GREEN: All tests passing with minimal implementation\n- [ ] REFACTOR: Code reviewed for quality, performance, security\n- [ ] Async context manager works (async with Database(...) as db)\n- [ ] All 7 tables created on first connect\n- [ ] Schema version tracked\n- [ ] All CRUD methods work correctly\n- [ ] Service ↔ Mode many-to-many via mode_services with ordering\n- [ ] Foreign key cascade ON DELETE CASCADE\n- [ ] ALL queries use parameterized statements (no SQL injection)\n- [ ] WAL mode enabled\n- [ ] `ruff check` passes\n- [ ] `mypy --strict` passes\n- [ ] Test coverage \u003e= 80%\n- [ ] Architecture compliant (checked against docs/ARCHITECTURE.md)","status":"open","priority":1,"issue_type":"task","owner":"ping@jaigouk.kim","created_at":"2026-02-06T21:36:44.440373929+01:00","created_by":"Jaigouk Kim","updated_at":"2026-02-06T21:45:59.260628907+01:00","dependencies":[{"issue_id":"gpumod-71s","depends_on_id":"gpumod-lti","type":"blocks","created_at":"2026-02-06T21:37:23.985124476+01:00","created_by":"Jaigouk Kim"},{"issue_id":"gpumod-71s","depends_on_id":"gpumod-0gc","type":"blocks","created_at":"2026-02-06T21:44:08.567951474+01:00","created_by":"Jaigouk Kim"}]}
{"id":"gpumod-7dp","title":"Implement ServiceRegistry","description":"## Goal\nImplement the ServiceRegistry that discovers, tracks, and maps services to their drivers.\n\n## Problem\nThe ServiceManager needs to: list all services, get a specific service, find which driver handles it, and discover service dependencies. The registry provides this lookup layer backed by SQLite.\n\n## Architecture Reference\nRead docs/ARCHITECTURE.md before starting. Key principles:\n- Registry depends on: db, models, base, all drivers\n- Registry is the bridge between DB data and driver instances\n- If you have a design question, update the ticket notes and tag ARCHITECT\n\n## Workflow: Red → Green → Refactor\n\n### RED: Write failing tests first\nCreate `tests/unit/test_registry.py`:\n- Use tmp_path DB fixture with pre-populated test services (one per driver type)\n- Test list_all() returns all 3 services\n- Test list_running() filters to only RUNNING/SLEEPING services (mock driver.status())\n- Test list_running() returns empty when all stopped\n- Test get() returns correct service by ID\n- Test get() raises KeyError for unknown service ID\n- Test get_driver() returns VLLMDriver for DriverType.VLLM\n- Test get_driver() returns LlamaCppDriver for DriverType.LLAMACPP\n- Test get_driver() returns FastAPIDriver for DriverType.FASTAPI\n- Test get_driver() raises ValueError for unknown driver type\n- Test get_dependents() finds services that depend on a given service\n- Test get_dependents() returns empty for service with no dependents\n- Test register_service() adds service to DB\n- Test unregister_service() removes service from DB\n- Test register_driver() allows adding custom driver types\n\nRun tests - they must ALL FAIL:\n```bash\nuv run pytest tests/unit/test_registry.py -v\n```\n\n### GREEN: Minimal implementation\nCreate `src/gpumod/services/registry.py` with ServiceRegistry class.\n\nRun tests - they must ALL PASS.\n\n### REFACTOR: Quality, Performance, Security\n1. **Code quality**: Clean separation, docstrings, consistent error types\n2. **Performance**: list_running() calls drivers concurrently with asyncio.gather\n3. **Security**: No injection risk in DB queries (parameterized via db.py)\n\n## Quality Gate (must pass before closing)\n```bash\nuv run ruff check src/gpumod/services/registry.py tests/unit/test_registry.py\nuv run mypy src/gpumod/services/registry.py --strict\nuv run pytest tests/unit/test_registry.py -v --cov=src/gpumod/services/registry --cov-report=term-missing --cov-fail-under=80\n```\nALL THREE must exit 0. Do not close this ticket until they do.\n\n## Acceptance Criteria\n- [ ] RED: All tests written and failing before implementation\n- [ ] GREEN: All tests passing with minimal implementation\n- [ ] REFACTOR: Code reviewed for quality, performance, security\n- [ ] Registry backed by Database (not in-memory)\n- [ ] get() raises KeyError for missing services\n- [ ] get_driver() maps DriverType to correct driver instance\n- [ ] list_running() queries actual driver status\n- [ ] Custom drivers can be registered\n- [ ] `ruff check` passes\n- [ ] `mypy --strict` passes\n- [ ] Test coverage \u003e= 80%\n- [ ] Architecture compliant (checked against docs/ARCHITECTURE.md)","status":"open","priority":1,"issue_type":"task","owner":"ping@jaigouk.kim","created_at":"2026-02-06T21:36:58.345941696+01:00","created_by":"Jaigouk Kim","updated_at":"2026-02-06T21:47:06.349838942+01:00","dependencies":[{"issue_id":"gpumod-7dp","depends_on_id":"gpumod-exy","type":"blocks","created_at":"2026-02-06T21:37:24.366019958+01:00","created_by":"Jaigouk Kim"},{"issue_id":"gpumod-7dp","depends_on_id":"gpumod-uwh","type":"blocks","created_at":"2026-02-06T21:37:24.397853482+01:00","created_by":"Jaigouk Kim"},{"issue_id":"gpumod-7dp","depends_on_id":"gpumod-b8b","type":"blocks","created_at":"2026-02-06T21:37:24.428186362+01:00","created_by":"Jaigouk Kim"},{"issue_id":"gpumod-7dp","depends_on_id":"gpumod-71s","type":"blocks","created_at":"2026-02-06T21:37:24.457888213+01:00","created_by":"Jaigouk Kim"}]}
{"id":"gpumod-7p3","title":"Implement LifecycleManager","description":"## Goal\nImplement the LifecycleManager that handles service start/stop with dependency ordering and health waiting.\n\n## Problem\nServices have dependencies. Starting must follow topological order (deps first), stopping must follow reverse order (dependents first). After starting, we must wait for health before declaring success.\n\n## Architecture Reference\nRead docs/ARCHITECTURE.md before starting. Key principles:\n- LifecycleManager depends on: registry, models\n- Orchestration logic lives here, not in drivers\n- If you have a design question, update the ticket notes and tag ARCHITECT\n\n## Workflow: Red → Green → Refactor\n\n### RED: Write failing tests first\nCreate `tests/unit/test_lifecycle.py`:\n- Mock ServiceRegistry with pre-configured services and drivers\n\nDependency test setup:\n```\nsvc-a (no deps)\nsvc-b (depends on svc-a)\nsvc-c (depends on svc-b) → chain: a → b → c\n```\n\nTests:\n- Test start(svc-a) with no deps: calls driver.start + waits for health\n- Test start(svc-c) with chain: starts svc-a first, then svc-b, then svc-c\n- Test start() skips already-running dependencies (doesn't re-start them)\n- Test stop(svc-a) with dependents: stops svc-c first, then svc-b, then svc-a\n- Test stop() skips already-stopped dependents\n- Test restart() calls stop then start in order\n- Test _wait_for_healthy returns immediately when health passes first try\n- Test _wait_for_healthy retries on initial failure, succeeds on 3rd try\n- Test _wait_for_healthy raises LifecycleError on timeout\n- Test LifecycleError message includes service_id, operation, reason\n\nRun tests - they must ALL FAIL:\n```bash\nuv run pytest tests/unit/test_lifecycle.py -v\n```\n\n### GREEN: Minimal implementation\nCreate `src/gpumod/services/lifecycle.py` with LifecycleManager and LifecycleError.\n\nRun tests - they must ALL PASS.\n\n### REFACTOR: Quality, Performance, Security\n1. **Code quality**: Clean recursive start/stop, docstrings, error messages\n2. **Performance**: \n   - Parallel start for independent deps (asyncio.gather where no ordering required)\n   - Configurable poll interval in _wait_for_healthy\n3. **Security**: No infinite recursion on circular deps (detect and raise)\n\n## Quality Gate (must pass before closing)\n```bash\nuv run ruff check src/gpumod/services/lifecycle.py tests/unit/test_lifecycle.py\nuv run mypy src/gpumod/services/lifecycle.py --strict\nuv run pytest tests/unit/test_lifecycle.py -v --cov=src/gpumod/services/lifecycle --cov-report=term-missing --cov-fail-under=80\n```\nALL THREE must exit 0. Do not close this ticket until they do.\n\n## Acceptance Criteria\n- [ ] RED: All tests written and failing before implementation\n- [ ] GREEN: All tests passing with minimal implementation\n- [ ] REFACTOR: Code reviewed for quality, performance, security\n- [ ] start() resolves and starts dependencies first (topological order)\n- [ ] stop() stops dependents before the service (reverse order)\n- [ ] Already-running services skipped during start\n- [ ] Already-stopped services skipped during stop\n- [ ] Health wait with configurable timeout and poll interval\n- [ ] LifecycleError on timeout with useful message\n- [ ] `ruff check` passes\n- [ ] `mypy --strict` passes\n- [ ] Test coverage \u003e= 80%\n- [ ] Architecture compliant (checked against docs/ARCHITECTURE.md)","status":"open","priority":1,"issue_type":"task","owner":"ping@jaigouk.kim","created_at":"2026-02-06T21:37:00.399244747+01:00","created_by":"Jaigouk Kim","updated_at":"2026-02-06T21:47:20.485827977+01:00","dependencies":[{"issue_id":"gpumod-7p3","depends_on_id":"gpumod-7dp","type":"blocks","created_at":"2026-02-06T21:37:24.546899057+01:00","created_by":"Jaigouk Kim"}]}
{"id":"gpumod-8ac","title":"Implement SleepController","description":"## Goal\nImplement the SleepController that manages sleep/wake operations across all services.\n\n## Problem\nGPU VRAM is scarce (24GB on RTX 4090). When services aren't being used, they should be put to sleep to free VRAM. The SleepController orchestrates this across different driver types with proper state validation.\n\n## Architecture Reference\nRead docs/ARCHITECTURE.md before starting. Key principles:\n- SleepController depends on: registry, models\n- State validation: only sleep RUNNING services, only wake SLEEPING services\n- Each driver has its own sleep mechanism (L1/L2 for vLLM, router for llama.cpp)\n- If you have a design question, update the ticket notes and tag ARCHITECT\n\n## Workflow: Red → Green → Refactor\n\n### RED: Write failing tests first\nCreate `tests/unit/test_sleep.py`:\n- Mock ServiceRegistry and all drivers\n\nTest setup: 3 services:\n- svc-vllm (supports_sleep=True, state=RUNNING)\n- svc-llamacpp (supports_sleep=True, state=SLEEPING)\n- svc-fastapi (supports_sleep=False, state=RUNNING)\n\nTests:\n- Test sleep() calls driver.sleep with correct level\n- Test sleep() is no-op when service already SLEEPING (idempotent)\n- Test sleep() raises SleepError for non-RUNNING service (e.g., STOPPED)\n- Test sleep() raises SleepError for driver that doesn't support sleep\n- Test sleep() raises KeyError for non-existent service\n- Test wake() calls driver.wake\n- Test wake() raises SleepError for non-SLEEPING service\n- Test wake() raises SleepError for driver that doesn't support wake\n- Test get_sleepable_services() returns only running services with supports_sleep=True\n- Test get_sleepable_services() excludes already-sleeping services\n- Test sleep_all() sleeps all running sleepable services, returns their IDs\n- Test sleep_all() skips already-sleeping services\n- Test wake_all() wakes all sleeping services, returns their IDs\n- Test wake_all() skips non-sleeping services\n- Test SleepError message includes service_id and reason\n\nRun tests - they must ALL FAIL:\n```bash\nuv run pytest tests/unit/test_sleep.py -v\n```\n\n### GREEN: Minimal implementation\nCreate `src/gpumod/services/sleep.py` with SleepController and SleepError.\n\nRun tests - they must ALL PASS.\n\n### REFACTOR: Quality, Performance, Security\n1. **Code quality**: Clear state machine documentation, consistent error messages\n2. **Performance**: sleep_all/wake_all could use asyncio.gather for concurrent operations\n3. **Security**: Validate sleep level parameter (only allow known values: l1, l2, router)\n\n## Quality Gate (must pass before closing)\n```bash\nuv run ruff check src/gpumod/services/sleep.py tests/unit/test_sleep.py\nuv run mypy src/gpumod/services/sleep.py --strict\nuv run pytest tests/unit/test_sleep.py -v --cov=src/gpumod/services/sleep --cov-report=term-missing --cov-fail-under=80\n```\nALL THREE must exit 0. Do not close this ticket until they do.\n\n## Acceptance Criteria\n- [ ] RED: All tests written and failing before implementation\n- [ ] GREEN: All tests passing with minimal implementation\n- [ ] REFACTOR: Code reviewed for quality, performance, security\n- [ ] sleep() validates state before sleeping\n- [ ] sleep() is idempotent (no-op if already sleeping)\n- [ ] wake() validates state before waking\n- [ ] SleepError with descriptive messages\n- [ ] sleep_all() and wake_all() operate on correct sets\n- [ ] Sleep level validated\n- [ ] `ruff check` passes\n- [ ] `mypy --strict` passes\n- [ ] Test coverage \u003e= 80%\n- [ ] Architecture compliant (checked against docs/ARCHITECTURE.md)","status":"open","priority":1,"issue_type":"task","owner":"ping@jaigouk.kim","created_at":"2026-02-06T21:37:04.818912083+01:00","created_by":"Jaigouk Kim","updated_at":"2026-02-06T21:47:57.620655969+01:00","dependencies":[{"issue_id":"gpumod-8ac","depends_on_id":"gpumod-7dp","type":"blocks","created_at":"2026-02-06T21:37:24.517622549+01:00","created_by":"Jaigouk Kim"}]}
{"id":"gpumod-8i5","title":"QA: Phase 1 quality gate","description":"## Goal\nRun the full quality gate for Phase 1 - ensure the entire codebase passes all checks together.\n\n## Problem\nIndividual tickets have their own quality gates, but the full codebase needs to pass as a unit. This catches cross-module issues (import cycles, type conflicts, test interactions).\n\n## Steps\n\n### 1. Full lint check\n```bash\nuv run ruff check src/ tests/\nuv run ruff format --check src/ tests/\n```\nFix any issues. No exceptions.\n\n### 2. Full type check (strict)\n```bash\nuv run mypy src/ --strict\n```\nFix any type errors. No `# type: ignore` without justifying comment.\n\n### 3. Full test suite with coverage\n```bash\nuv run pytest tests/ -v --cov=src/gpumod --cov-report=term-missing --cov-fail-under=80\n```\n- ALL tests must pass\n- Combined coverage must be \u003e= 80%\n- Note any modules below 80% and create tickets if needed\n\n### 4. Architecture compliance review\n- Read docs/ARCHITECTURE.md\n- Verify module dependency graph matches documented graph (no undocumented deps)\n- Verify no circular imports: `python -c \"import gpumod.services.manager\"`\n- Verify all interface contracts are respected (ServiceDriver, Database, etc.)\n\n### 5. Security review\n- systemd.py: unit name validation tested, command allowlist enforced\n- db.py: all queries use parameterized statements\n- drivers: HTTP calls only to localhost, timeouts on all requests\n- No eval(), exec(), shell=True, or string-formatted SQL anywhere\n- Run: `grep -r \"shell=True\\|\\.format.*sql\\|f\\\".*SELECT\\|eval(\\|exec(\" src/`\n\n### 6. Performance review\n- get_status() uses asyncio.gather (not sequential loops)\n- All I/O is async (no blocking calls in async functions)\n- HTTP clients have timeouts\n- DB connections properly closed (context managers)\n\n### 7. Create tickets for issues found\n```bash\nbd create --title=\"Fix: {description}\" --type=bug --priority=1\n```\n\n## Acceptance Criteria\n- [ ] `uv run ruff check src/ tests/` exits 0\n- [ ] `uv run ruff format --check src/ tests/` exits 0\n- [ ] `uv run mypy src/ --strict` exits 0\n- [ ] `uv run pytest tests/ -v --cov=src/gpumod --cov-fail-under=80` exits 0\n- [ ] No circular imports\n- [ ] No security issues (injection, hardcoded secrets, etc.)\n- [ ] Module dependency graph matches ARCHITECTURE.md\n- [ ] All public APIs have docstrings\n- [ ] Bug tickets created for any issues found\n- [ ] Phase 1 epic (gpumod-qf3) can be closed after this passes","status":"open","priority":0,"issue_type":"task","owner":"ping@jaigouk.kim","created_at":"2026-02-06T21:37:12.384960868+01:00","created_by":"Jaigouk Kim","updated_at":"2026-02-06T21:48:36.547563342+01:00","dependencies":[{"issue_id":"gpumod-8i5","depends_on_id":"gpumod-6gy","type":"blocks","created_at":"2026-02-06T21:37:24.695067895+01:00","created_by":"Jaigouk Kim"}]}
{"id":"gpumod-b8b","title":"Implement FastAPIDriver","description":"## Goal\nImplement the FastAPI service driver for custom FastAPI servers (qwen3-asr, qwen3-tts, etc.).\n\n## Problem\nSome GPU services are custom FastAPI apps with non-standard conventions. They need a generic driver with configurable health endpoint and no sleep support by default.\n\n## Architecture Reference\nRead docs/ARCHITECTURE.md before starting. Key principles:\n- Drivers are thin: wrap external APIs, no orchestration logic\n- status() and health_check() must NEVER raise exceptions\n- If you have a design question, update the ticket notes and tag ARCHITECT\n\n## Workflow: Red → Green → Refactor\n\n### RED: Write failing tests first\nCreate `tests/unit/test_fastapi_driver.py`:\n\nHelper: `make_fastapi_service(health_endpoint=\"/health\")` returning Service with driver=DriverType.FASTAPI\n\nTests (mock systemd + httpx):\n- Test start() calls systemd.start\n- Test start() raises ValueError if no unit_name\n- Test stop() calls systemd.stop\n- Test health_check() uses service.health_endpoint (custom endpoint)\n- Test health_check() uses \"/health\" as default when health_endpoint is None\n- Test health_check() returns True on 200\n- Test health_check() returns False on connection error\n- Test health_check() returns False on non-200 (e.g., 503)\n- Test status() returns STOPPED when unit inactive\n- Test status() returns RUNNING when active + healthy\n- Test status() returns UNHEALTHY when active + health fails\n- Test status() returns UNKNOWN on unexpected error (never raises)\n- Test supports_sleep returns False\n\nRun tests - they must ALL FAIL:\n```bash\nuv run pytest tests/unit/test_fastapi_driver.py -v\n```\n\n### GREEN: Minimal implementation\nCreate `src/gpumod/services/drivers/fastapi.py` with FastAPIDriver class.\n\nRun tests - they must ALL PASS.\n\n### REFACTOR: Quality, Performance, Security\n1. **Code quality**: Consistent with other drivers, docstrings\n2. **Performance**: Shorter HTTP timeout (5s vs 10s) since FastAPI servers are simpler\n3. **Security**:\n   - health_endpoint path validated (no SSRF via crafted paths)\n   - HTTP calls only to localhost\n   - Timeout prevents hanging\n\n## Quality Gate (must pass before closing)\n```bash\nuv run ruff check src/gpumod/services/drivers/fastapi.py tests/unit/test_fastapi_driver.py\nuv run mypy src/gpumod/services/drivers/fastapi.py --strict\nuv run pytest tests/unit/test_fastapi_driver.py -v --cov=src/gpumod/services/drivers/fastapi --cov-report=term-missing --cov-fail-under=80\n```\nALL THREE must exit 0. Do not close this ticket until they do.\n\n## Acceptance Criteria\n- [ ] RED: All tests written and failing before implementation\n- [ ] GREEN: All tests passing with minimal implementation\n- [ ] REFACTOR: Code reviewed for quality, performance, security\n- [ ] Health endpoint is configurable per-service\n- [ ] No sleep/wake support (supports_sleep=False)\n- [ ] health_check() and status() never raise\n- [ ] `ruff check` passes\n- [ ] `mypy --strict` passes\n- [ ] Test coverage \u003e= 80%\n- [ ] Architecture compliant (checked against docs/ARCHITECTURE.md)","status":"open","priority":1,"issue_type":"task","owner":"ping@jaigouk.kim","created_at":"2026-02-06T21:36:56.645581293+01:00","created_by":"Jaigouk Kim","updated_at":"2026-02-06T21:46:48.238547826+01:00","dependencies":[{"issue_id":"gpumod-b8b","depends_on_id":"gpumod-vpv","type":"blocks","created_at":"2026-02-06T21:37:24.278007587+01:00","created_by":"Jaigouk Kim"},{"issue_id":"gpumod-b8b","depends_on_id":"gpumod-kje","type":"blocks","created_at":"2026-02-06T21:37:24.306495709+01:00","created_by":"Jaigouk Kim"},{"issue_id":"gpumod-b8b","depends_on_id":"gpumod-2kc","type":"blocks","created_at":"2026-02-06T21:37:24.336150136+01:00","created_by":"Jaigouk Kim"}]}
{"id":"gpumod-e0c","title":"Phase 5: AI Planning \u0026 Polish","description":"AI-assisted planning (gpumod plan), configurable LLM backends, remove all hardcoded paths, documentation, example presets, open-source preparation, v0.1.0 release.","status":"open","priority":3,"issue_type":"feature","owner":"ping@jaigouk.kim","created_at":"2026-02-06T21:36:21.974713204+01:00","created_by":"Jaigouk Kim","updated_at":"2026-02-06T21:36:21.974713204+01:00","dependencies":[{"issue_id":"gpumod-e0c","depends_on_id":"gpumod-1nb","type":"blocks","created_at":"2026-02-06T21:36:29.21291024+01:00","created_by":"Jaigouk Kim"}]}
{"id":"gpumod-exy","title":"Implement VLLMDriver","description":"## Goal\nImplement the vLLM service driver - the most important driver since vLLM powers embedding and chat services.\n\n## Problem\nvLLM services are managed via systemd and expose HTTP APIs for health, sleep, and wake. The driver must wrap both systemd lifecycle and HTTP API interactions.\n\n## Architecture Reference\nRead docs/ARCHITECTURE.md before starting. Key principles:\n- Drivers are thin: wrap external APIs, no orchestration logic\n- status() and health_check() must NEVER raise exceptions\n- sleep/wake use HTTP endpoints on the running vLLM process\n- If you have a design question, update the ticket notes and tag ARCHITECT\n\n## Context: vLLM HTTP API\n- `GET /health` → 200 if healthy\n- `POST /sleep` body `{\"level\": \"l1\"|\"l2\"}` → puts model to sleep\n- `POST /wake` → wakes model from sleep\n\n## Workflow: Red → Green → Refactor\n\n### RED: Write failing tests first\nCreate `tests/unit/test_vllm_driver.py`:\n\nHelper: `make_vllm_service()` returning Service(id=\"test-vllm\", name=\"Test vLLM\", driver=DriverType.VLLM, vram_mb=5000, port=8200, unit_name=\"test-vllm.service\")\n\nTests (mock systemd module + httpx.AsyncClient):\n- Test start() calls systemd.start with correct unit_name\n- Test start() raises ValueError if service has no unit_name\n- Test stop() calls systemd.stop with correct unit_name\n- Test health_check() returns True on 200 response\n- Test health_check() returns False on connection error (httpx.ConnectError)\n- Test health_check() returns False on non-200 status code\n- Test health_check() returns False when port is None\n- Test sleep() sends POST /sleep with {\"level\": \"l1\"} body\n- Test sleep() sends POST /sleep with {\"level\": \"l2\"} body\n- Test wake() sends POST /wake\n- Test status() returns STOPPED when systemd unit is inactive\n- Test status() returns RUNNING when unit active + health OK + not sleeping\n- Test status() returns SLEEPING when unit active + sleeping\n- Test status() returns UNHEALTHY when unit active + health fails\n- Test status() returns UNKNOWN on unexpected errors (never raises)\n- Test supports_sleep returns True\n\nRun tests - they must ALL FAIL:\n```bash\nuv run pytest tests/unit/test_vllm_driver.py -v\n# Expected: ALL FAIL\n```\n\n### GREEN: Minimal implementation\nCreate `src/gpumod/services/drivers/vllm.py`:\n\n```python\nimport httpx\nfrom gpumod.models import Service, ServiceStatus, ServiceState, SleepMode\nfrom gpumod.services.base import ServiceDriver\nfrom gpumod.services import systemd\n\nclass VLLMDriver(ServiceDriver):\n    def __init__(self, http_timeout: float = 10.0) -\u003e None:\n        self._http_timeout = http_timeout\n\n    async def start(self, service: Service) -\u003e None: ...\n    async def stop(self, service: Service) -\u003e None: ...\n    async def status(self, service: Service) -\u003e ServiceStatus: ...\n    async def health_check(self, service: Service) -\u003e bool: ...\n    async def sleep(self, service: Service, level: str = \"l1\") -\u003e None: ...\n    async def wake(self, service: Service) -\u003e None: ...\n\n    @property\n    def supports_sleep(self) -\u003e bool:\n        return True\n```\n\nRun tests - they must ALL PASS:\n```bash\nuv run pytest tests/unit/test_vllm_driver.py -v\n# Expected: ALL PASS\n```\n\n### REFACTOR: Quality, Performance, Security\n1. **Code quality**: Docstrings, consistent error messages, clean method signatures\n2. **Performance**: HTTP timeout on all requests, avoid creating new AsyncClient per call if possible\n3. **Security**:\n   - HTTP calls only to localhost (no user-controlled hosts)\n   - Timeout prevents hanging on unresponsive services\n   - No secrets in HTTP calls\n   - Input validation on sleep level parameter\n\n## Quality Gate (must pass before closing)\n```bash\nuv run ruff check src/gpumod/services/drivers/vllm.py tests/unit/test_vllm_driver.py\nuv run mypy src/gpumod/services/drivers/vllm.py --strict\nuv run pytest tests/unit/test_vllm_driver.py -v --cov=src/gpumod/services/drivers/vllm --cov-report=term-missing --cov-fail-under=80\n```\nALL THREE must exit 0. Do not close this ticket until they do.\n\n## Acceptance Criteria\n- [ ] RED: All tests written and failing before implementation\n- [ ] GREEN: All tests passing with minimal implementation\n- [ ] REFACTOR: Code reviewed for quality, performance, security\n- [ ] start/stop delegate to systemd module\n- [ ] health_check never raises (returns bool)\n- [ ] status() never raises (returns ServiceStatus with appropriate state)\n- [ ] sleep/wake use correct HTTP endpoints and payload\n- [ ] All HTTP calls use configurable timeout\n- [ ] ValueError for services missing unit_name\n- [ ] `ruff check` passes\n- [ ] `mypy --strict` passes\n- [ ] Test coverage \u003e= 80%\n- [ ] Architecture compliant (checked against docs/ARCHITECTURE.md)","status":"open","priority":1,"issue_type":"task","owner":"ping@jaigouk.kim","created_at":"2026-02-06T21:36:52.665152933+01:00","created_by":"Jaigouk Kim","updated_at":"2026-02-06T21:46:24.115876593+01:00","dependencies":[{"issue_id":"gpumod-exy","depends_on_id":"gpumod-vpv","type":"blocks","created_at":"2026-02-06T21:37:24.102358389+01:00","created_by":"Jaigouk Kim"},{"issue_id":"gpumod-exy","depends_on_id":"gpumod-kje","type":"blocks","created_at":"2026-02-06T21:37:24.131545917+01:00","created_by":"Jaigouk Kim"},{"issue_id":"gpumod-exy","depends_on_id":"gpumod-2kc","type":"blocks","created_at":"2026-02-06T21:37:24.160500729+01:00","created_by":"Jaigouk Kim"}]}
{"id":"gpumod-kje","title":"Create Pydantic models (models.py)","description":"## Goal\nDefine all data models used throughout gpumod as Pydantic v2 models and Python enums. These are the shared vocabulary for the entire codebase.\n\n## Problem\nAll components (drivers, manager, DB, CLI) need a common set of typed data structures. Without these, each component would define its own ad-hoc types, causing inconsistency.\n\n## Architecture Reference\nRead docs/ARCHITECTURE.md before starting. Models must follow:\n- \"Models are dumb\" principle: data only, no business logic\n- All models in a single file (models.py)\n- If you have a design question, update the ticket notes and tag ARCHITECT\n\n## Workflow: Red → Green → Refactor\n\n### RED: Write failing tests first\nCreate `tests/unit/test_models.py` with tests for:\n- Enum membership and string values for ServiceState, DriverType, SleepMode\n- Service model validation: required fields (id, name, driver, vram_mb), defaults\n- ServiceStatus with all field combinations (None-able fields)\n- Mode serialization/deserialization round-trip\n- ModeResult with success=True and success=False\n- GPUInfo, VRAMUsage field validation\n- Invalid DriverType raises ValidationError\n- Extra fields are rejected (model_config strict or forbid)\n\nRun tests - they must ALL FAIL:\n```bash\nuv run pytest tests/unit/test_models.py -v\n# Expected: ALL FAIL (classes don't exist yet)\n```\n\n### GREEN: Minimal implementation\nCreate `src/gpumod/models.py` with just enough code to pass all tests:\n\n#### Enums\n```python\nclass ServiceState(str, Enum):\n    UNKNOWN = \"unknown\"\n    STOPPED = \"stopped\"\n    STARTING = \"starting\"\n    RUNNING = \"running\"\n    SLEEPING = \"sleeping\"\n    UNHEALTHY = \"unhealthy\"\n    STOPPING = \"stopping\"\n    FAILED = \"failed\"\n\nclass DriverType(str, Enum):\n    VLLM = \"vllm\"\n    LLAMACPP = \"llamacpp\"\n    FASTAPI = \"fastapi\"\n    DOCKER = \"docker\"\n\nclass SleepMode(str, Enum):\n    NONE = \"none\"\n    L1 = \"l1\"\n    L2 = \"l2\"\n    ROUTER = \"router\"\n```\n\n#### Core Models (Pydantic BaseModel)\n```python\nclass ServiceStatus(BaseModel):\n    state: ServiceState\n    vram_mb: int | None = None\n    uptime_seconds: int | None = None\n    health_ok: bool | None = None\n    sleep_level: SleepMode | None = None\n    last_error: str | None = None\n\nclass Service(BaseModel):\n    id: str\n    name: str\n    driver: DriverType\n    port: int | None = None\n    vram_mb: int\n    sleep_mode: SleepMode = SleepMode.NONE\n    health_endpoint: str = \"/health\"\n    model_id: str | None = None\n    unit_name: str | None = None\n    depends_on: list[str] = []\n    startup_timeout: int = 120\n    extra_config: dict[str, Any] = {}\n\nclass Mode(BaseModel):\n    id: str\n    name: str\n    description: str = \"\"\n    service_ids: list[str] = []\n    total_vram_mb: int | None = None\n\nclass GPUInfo(BaseModel):\n    name: str\n    vram_total_mb: int\n    driver: str\n\nclass VRAMUsage(BaseModel):\n    used_mb: int\n    free_mb: int\n\nclass ModeResult(BaseModel):\n    success: bool\n    error: str | None = None\n    services_started: list[str] = []\n    services_stopped: list[str] = []\n\nclass ServiceInfo(BaseModel):\n    service: Service\n    status: ServiceStatus\n\nclass SystemStatus(BaseModel):\n    mode: str | None = None\n    gpu: GPUInfo | None = None\n    vram_used_mb: int = 0\n    vram_total_mb: int = 0\n    services: list[ServiceInfo] = []\n```\n\nRun tests - they must ALL PASS:\n```bash\nuv run pytest tests/unit/test_models.py -v\n# Expected: ALL PASS\n```\n\n### REFACTOR: Quality, Performance, Security\n1. **Code quality**: Check naming consistency, remove duplication, ensure docstrings\n2. **Performance**: Verify model_config settings (e.g., frozen for immutable models where appropriate)\n3. **Security**: Ensure no arbitrary code execution paths, validate string fields don't allow injection\n\n## Quality Gate (must pass before closing)\n```bash\nuv run ruff check src/gpumod/models.py tests/unit/test_models.py\nuv run mypy src/gpumod/models.py --strict\nuv run pytest tests/unit/test_models.py -v --cov=src/gpumod/models --cov-report=term-missing --cov-fail-under=80\n```\nALL THREE must exit 0. Do not close this ticket until they do.\n\n## Acceptance Criteria\n- [ ] RED: All tests written and failing before implementation\n- [ ] GREEN: All tests passing with minimal implementation\n- [ ] REFACTOR: Code reviewed for quality, performance, security\n- [ ] All enums have correct string values\n- [ ] Service model enforces required fields (id, name, driver, vram_mb)\n- [ ] Default values work correctly (health_endpoint=\"/health\", etc.)\n- [ ] JSON serialization round-trip preserves all fields\n- [ ] `ruff check` passes\n- [ ] `mypy --strict` passes\n- [ ] Test coverage \u003e= 80% for models.py\n- [ ] Architecture compliant (checked against docs/ARCHITECTURE.md)","status":"in_progress","priority":1,"issue_type":"task","owner":"ping@jaigouk.kim","created_at":"2026-02-06T21:36:48.837867246+01:00","created_by":"Jaigouk Kim","updated_at":"2026-02-06T22:18:23.253262341+01:00","dependencies":[{"issue_id":"gpumod-kje","depends_on_id":"gpumod-lti","type":"blocks","created_at":"2026-02-06T21:37:24.01640694+01:00","created_by":"Jaigouk Kim"},{"issue_id":"gpumod-kje","depends_on_id":"gpumod-0gc","type":"blocks","created_at":"2026-02-06T21:44:08.478830362+01:00","created_by":"Jaigouk Kim"}]}
{"id":"gpumod-lti","title":"Scaffold project structure (pyproject.toml, src/gpumod)","description":"## Goal\nCreate the foundational project structure for gpumod - a GPU service management tool that orchestrates ML services (vLLM, llama.cpp, FastAPI) on Linux with NVIDIA GPUs.\n\n## Problem\nThere is no project structure yet. All subsequent work depends on having pyproject.toml, source layout, and dev tooling configured.\n\n## Steps\n\n### 1. Create directory structure\n```\nsrc/gpumod/\n├── __init__.py          # Version string, package metadata\n├── py.typed             # PEP 561 marker for type checking\n└── services/\n    ├── __init__.py\n    └── drivers/\n        └── __init__.py\ntests/\n├── __init__.py\n├── conftest.py          # Shared fixtures\n└── unit/\n    └── __init__.py\ndocs/                    # Architecture and design docs\n```\n\n### 2. Create pyproject.toml\n- Build system: hatchling\n- Python: \u003e=3.11\n- Runtime deps: httpx, pydantic\u003e=2.0, aiosqlite, typer[all], rich\u003e=14.0, jinja2\n- Dev deps: pytest, pytest-asyncio, pytest-cov, mypy, ruff, types-aiofiles\n- Configure ruff: target Python 3.11, select rules (E, F, I, UP, B, SIM, TCH)\n- Configure mypy: strict mode, disallow_untyped_defs=true\n- Configure pytest: asyncio_mode=auto, testpaths=[\"tests\"]\n- Configure coverage: fail_under=80\n\n### 3. Create conftest.py with basic fixtures\n- tmp_path-based test database fixture\n- Event loop fixture for async tests\n\n### 4. Verify toolchain\n- `uv sync --dev` installs successfully\n- `uv run ruff check src/` passes (no files to check is OK)\n- `uv run mypy src/` passes\n- `uv run pytest tests/` passes (no tests collected is OK)\n\n## Quality Gate (must pass before closing)\n```bash\nuv sync --dev              # Installs without errors\nuv run ruff check src/ tests/    # Lint clean\nuv run mypy src/ --strict        # Type clean\nuv run pytest tests/             # No failures\n```\n\n## Acceptance Criteria\n- [ ] `uv sync --dev` completes without errors\n- [ ] `uv run ruff check src/ tests/` exits 0\n- [ ] `uv run mypy src/ --strict` exits 0\n- [ ] `uv run pytest` exits 0\n- [ ] `src/gpumod/__init__.py` exports `__version__ = \"0.1.0\"`\n- [ ] `src/gpumod/py.typed` exists (empty file)\n- [ ] All directories have `__init__.py`\n- [ ] `docs/` directory exists\n- [ ] pyproject.toml has coverage fail_under=80","status":"closed","priority":1,"issue_type":"task","owner":"ping@jaigouk.kim","created_at":"2026-02-06T21:36:36.758415589+01:00","created_by":"Jaigouk Kim","updated_at":"2026-02-06T21:56:25.845010905+01:00","closed_at":"2026-02-06T21:56:25.845010905+01:00","close_reason":"Scaffold complete: pyproject.toml, src/gpumod/, tests/, docs/ all created. uv sync, ruff, mypy all pass."}
{"id":"gpumod-qf3","title":"Phase 1: Foundation (Services Layer)","description":"## Goal\nBuild the core services layer - the heart of gpumod.\n\n## Components (14 tickets)\n1. **gpumod-lti**: Project scaffold (pyproject.toml, src layout, toolchain)\n2. **gpumod-0gc**: ARCHITECT: Design Phase 1 + create docs/ARCHITECTURE.md\n3. **gpumod-kje**: Pydantic models (Service, Mode, GPUInfo, enums)\n4. **gpumod-vpv**: ServiceDriver ABC (abstract base for all drivers)\n5. **gpumod-2kc**: systemd helper (async systemctl wrapper)\n6. **gpumod-71s**: SQLite DB layer (schema, CRUD, migrations)\n7. **gpumod-exy**: VLLMDriver (systemd + HTTP sleep/wake)\n8. **gpumod-uwh**: LlamaCppDriver (systemd + router mode load/unload)\n9. **gpumod-b8b**: FastAPIDriver (systemd + configurable health)\n10. **gpumod-7dp**: ServiceRegistry (service ↔ driver mapping)\n11. **gpumod-7p3**: LifecycleManager (dependency-ordered start/stop)\n12. **gpumod-zl5**: VRAMTracker (nvidia-smi parsing)\n13. **gpumod-8ac**: SleepController (sleep/wake orchestration)\n14. **gpumod-6gy**: ServiceManager (top-level orchestrator)\n15. **gpumod-8i5**: QA gate (lint, typecheck, tests, coverage, security)\n\n## Workflow\n- ARCHITECT creates docs/ARCHITECTURE.md first (gpumod-0gc)\n- DEVELOPER follows Red→Green→Refactor for each ticket\n- Every ticket has quality gate: ruff + mypy --strict + pytest coverage \u003e= 80%\n- No ticket closes without passing all checks\n- DEVELOPER communicates with ARCHITECT on design questions via ticket notes\n\n## Dependency Chain\nscaffold → ARCHITECTURE.md → [models, ABC, systemd, DB] → [3 drivers] → registry → [lifecycle, sleep, vram] → manager → QA\n\n## Quality Bar\n- TDD: Red (failing tests) → Green (minimal impl) → Refactor (quality, perf, security)\n- ruff check: No lint errors\n- mypy --strict: Full type safety\n- pytest coverage \u003e= 80% per module\n- Security: No injection, no hardcoded secrets, timeouts on all I/O","status":"open","priority":1,"issue_type":"feature","owner":"ping@jaigouk.kim","created_at":"2026-02-06T21:36:14.47723881+01:00","created_by":"Jaigouk Kim","updated_at":"2026-02-06T21:48:49.979594651+01:00"}
{"id":"gpumod-sa3","title":"gpumod v0.1.0 - GPU Service Manager","description":"## Goal\nBuild gpumod - an open-source GPU service management tool for orchestrating ML services (vLLM, llama.cpp, FastAPI) on single-GPU Linux machines.\n\n## Problem\nManaging multiple ML services on a single GPU (e.g., RTX 4090 24GB) requires careful VRAM budgeting, service lifecycle coordination, sleep/wake management, and mode switching. Currently done manually with hardcoded scripts.\n\n## Architecture\n- Services Layer: ServiceDriver ABC with VLLMDriver, LlamaCppDriver, FastAPIDriver\n- Config Layer: SQLite DB for services, modes, settings + Jinja2 templates\n- System Layer: systemd, nvidia-smi, HTTP health checks\n- User Interfaces: CLI (Typer/Rich), Interactive TUI (Textual), MCP Server (FastMCP)\n\n## Phases\n1. Foundation (Services Layer) - Core abstractions and drivers\n2. Templates \u0026 Model Registry - Jinja2 templates, YAML presets, HuggingFace fetcher\n3. CLI \u0026 Visualization - Typer CLI, Rich dashboard, VRAM ASCII art\n4. Simulation \u0026 MCP Server - Pre-simulation engine, FastMCP tools\n5. AI Planning \u0026 Polish - LLM-assisted planning, docs, open-source prep","status":"open","priority":1,"issue_type":"feature","owner":"ping@jaigouk.kim","created_at":"2026-02-06T21:36:07.567625419+01:00","created_by":"Jaigouk Kim","updated_at":"2026-02-06T21:42:44.090140677+01:00"}
{"id":"gpumod-uwh","title":"Implement LlamaCppDriver","description":"## Goal\nImplement the llama.cpp service driver for managing llama-server instances in router mode.\n\n## Problem\nllama.cpp server in router mode can load/unload models dynamically. Sleep means unloading the model (freeing VRAM) while keeping the server process running. This is fundamentally different from vLLM sleep.\n\n## Architecture Reference\nRead docs/ARCHITECTURE.md before starting. Key principles:\n- Drivers are thin: wrap external APIs, no orchestration logic\n- status() and health_check() must NEVER raise exceptions\n- If you have a design question, update the ticket notes and tag ARCHITECT\n\n## Context: llama-server Router Mode API\n- `GET /health` → 200 if server is up\n- `GET /models` → JSON list of loaded models (empty = sleeping/no model)\n- `POST /models/load` body `{\"model\": \"/path/to/model.gguf\"}` → load model into VRAM\n- `POST /models/unload` body `{\"model\": \"model_name\"}` → unload model (free VRAM)\n\n## Workflow: Red → Green → Refactor\n\n### RED: Write failing tests first\nCreate `tests/unit/test_llamacpp_driver.py`:\n\nHelper: `make_llamacpp_service()` returning Service with:\n- driver=DriverType.LLAMACPP, port=7070, unit_name=\"glm-code.service\"\n- extra_config={\"model_name\": \"devstral\", \"model_path\": \"/models/devstral.gguf\"}\n\nTests (mock systemd module + httpx.AsyncClient):\n- Test start() calls systemd.start with correct unit_name\n- Test start() raises ValueError if no unit_name\n- Test stop() calls systemd.stop\n- Test health_check() returns True on 200\n- Test health_check() returns False on connection error\n- Test status() returns STOPPED when systemd unit inactive\n- Test status() returns SLEEPING when unit active + /models returns empty list\n- Test status() returns RUNNING when unit active + /models returns loaded models\n- Test status() returns UNKNOWN on error (never raises)\n- Test sleep() sends POST /models/unload with model_name from extra_config\n- Test sleep() uses model_id as fallback when model_name not in extra_config\n- Test wake() sends POST /models/load with model_path from extra_config\n- Test _get_loaded_models parses JSON response correctly\n- Test _get_loaded_models returns empty list on connection error\n- Test supports_sleep returns True\n\nRun tests - they must ALL FAIL:\n```bash\nuv run pytest tests/unit/test_llamacpp_driver.py -v\n```\n\n### GREEN: Minimal implementation\nCreate `src/gpumod/services/drivers/llamacpp.py` with LlamaCppDriver class.\n\nRun tests - they must ALL PASS.\n\n### REFACTOR: Quality, Performance, Security\n1. **Code quality**: Docstrings, method naming consistent with VLLMDriver\n2. **Performance**: HTTP timeout on all requests\n3. **Security**:\n   - model_path validated (no path traversal in load requests)\n   - HTTP calls only to localhost\n   - Timeout prevents hanging\n\n## Quality Gate (must pass before closing)\n```bash\nuv run ruff check src/gpumod/services/drivers/llamacpp.py tests/unit/test_llamacpp_driver.py\nuv run mypy src/gpumod/services/drivers/llamacpp.py --strict\nuv run pytest tests/unit/test_llamacpp_driver.py -v --cov=src/gpumod/services/drivers/llamacpp --cov-report=term-missing --cov-fail-under=80\n```\nALL THREE must exit 0. Do not close this ticket until they do.\n\n## Acceptance Criteria\n- [ ] RED: All tests written and failing before implementation\n- [ ] GREEN: All tests passing with minimal implementation\n- [ ] REFACTOR: Code reviewed for quality, performance, security\n- [ ] Router-mode sleep: unload model via POST /models/unload\n- [ ] Router-mode wake: load model via POST /models/load\n- [ ] Status distinguishes RUNNING (model loaded) from SLEEPING (no model)\n- [ ] Model name/path read from service.extra_config\n- [ ] status() and health_check() never raise\n- [ ] `ruff check` passes\n- [ ] `mypy --strict` passes\n- [ ] Test coverage \u003e= 80%\n- [ ] Architecture compliant (checked against docs/ARCHITECTURE.md)","status":"open","priority":1,"issue_type":"task","owner":"ping@jaigouk.kim","created_at":"2026-02-06T21:36:54.678587485+01:00","created_by":"Jaigouk Kim","updated_at":"2026-02-06T21:46:38.359808033+01:00","dependencies":[{"issue_id":"gpumod-uwh","depends_on_id":"gpumod-vpv","type":"blocks","created_at":"2026-02-06T21:37:24.190050881+01:00","created_by":"Jaigouk Kim"},{"issue_id":"gpumod-uwh","depends_on_id":"gpumod-kje","type":"blocks","created_at":"2026-02-06T21:37:24.219335141+01:00","created_by":"Jaigouk Kim"},{"issue_id":"gpumod-uwh","depends_on_id":"gpumod-2kc","type":"blocks","created_at":"2026-02-06T21:37:24.248976856+01:00","created_by":"Jaigouk Kim"}]}
{"id":"gpumod-vpv","title":"Implement ServiceDriver ABC (base.py)","description":"## Goal\nCreate the abstract base class that all service drivers must implement. This defines the contract for managing any GPU service.\n\n## Problem\ngpumod manages multiple types of GPU services (vLLM, llama.cpp, FastAPI, Docker). Each has different start/stop/health mechanics. We need a common interface so the ServiceManager can treat all services uniformly.\n\n## Architecture Reference\nRead docs/ARCHITECTURE.md before starting. Key principles:\n- \"Drivers are thin\": wrap external APIs only, no orchestration\n- ServiceDriver defines the contract; implementations in drivers/\n- If you have a design question, update the ticket notes and tag ARCHITECT\n\n## Workflow: Red → Green → Refactor\n\n### RED: Write failing tests first\nCreate `tests/unit/test_service_driver.py`:\n- Test that ServiceDriver cannot be instantiated directly (ABC)\n- Test that a subclass missing any abstract method raises TypeError\n- Test that a minimal concrete subclass (all 4 methods) can be instantiated\n- Test that default sleep() raises NotImplementedError with driver name in message\n- Test that default wake() raises NotImplementedError with driver name in message\n- Test that default supports_sleep returns False\n- Test that a subclass overriding supports_sleep can return True\n\nRun tests - they must ALL FAIL:\n```bash\nuv run pytest tests/unit/test_service_driver.py -v\n# Expected: ALL FAIL\n```\n\n### GREEN: Minimal implementation\nCreate `src/gpumod/services/base.py`:\n\n```python\nfrom abc import ABC, abstractmethod\nfrom gpumod.models import Service, ServiceStatus\n\nclass ServiceDriver(ABC):\n    \"\"\"Base class for service drivers.\"\"\"\n\n    @abstractmethod\n    async def start(self, service: Service) -\u003e None:\n        \"\"\"Start the service. Raises RuntimeError on failure.\"\"\"\n\n    @abstractmethod\n    async def stop(self, service: Service) -\u003e None:\n        \"\"\"Stop the service. Raises RuntimeError on failure.\"\"\"\n\n    @abstractmethod\n    async def status(self, service: Service) -\u003e ServiceStatus:\n        \"\"\"Get current service status. Never raises - returns UNKNOWN on error.\"\"\"\n\n    @abstractmethod\n    async def health_check(self, service: Service) -\u003e bool:\n        \"\"\"Return True if healthy, False otherwise. Never raises.\"\"\"\n\n    async def sleep(self, service: Service, level: str = \"l1\") -\u003e None:\n        raise NotImplementedError(f\"{self.__class__.__name__} does not support sleep\")\n\n    async def wake(self, service: Service) -\u003e None:\n        raise NotImplementedError(f\"{self.__class__.__name__} does not support wake\")\n\n    @property\n    def supports_sleep(self) -\u003e bool:\n        return False\n```\n\nRun tests - they must ALL PASS:\n```bash\nuv run pytest tests/unit/test_service_driver.py -v\n# Expected: ALL PASS\n```\n\n### REFACTOR: Quality, Performance, Security\n1. **Code quality**: Docstrings on class and all methods, consistent param naming\n2. **Performance**: N/A for ABC (no runtime code)\n3. **Security**: Ensure ABC contract documents that status()/health_check() must not raise\n\n## Quality Gate (must pass before closing)\n```bash\nuv run ruff check src/gpumod/services/base.py tests/unit/test_service_driver.py\nuv run mypy src/gpumod/services/base.py --strict\nuv run pytest tests/unit/test_service_driver.py -v --cov=src/gpumod/services/base --cov-report=term-missing --cov-fail-under=80\n```\nALL THREE must exit 0. Do not close this ticket until they do.\n\n## Acceptance Criteria\n- [ ] RED: All tests written and failing before implementation\n- [ ] GREEN: All tests passing with minimal implementation\n- [ ] REFACTOR: Code reviewed for quality, performance, security\n- [ ] ServiceDriver is abstract (cannot be instantiated)\n- [ ] Missing abstract methods prevent instantiation\n- [ ] sleep/wake have defaults that raise NotImplementedError\n- [ ] supports_sleep defaults to False\n- [ ] `ruff check` passes\n- [ ] `mypy --strict` passes\n- [ ] Test coverage \u003e= 80%\n- [ ] Architecture compliant (checked against docs/ARCHITECTURE.md)","status":"open","priority":1,"issue_type":"task","owner":"ping@jaigouk.kim","created_at":"2026-02-06T21:36:50.665202461+01:00","created_by":"Jaigouk Kim","updated_at":"2026-02-06T21:45:12.622241667+01:00","dependencies":[{"issue_id":"gpumod-vpv","depends_on_id":"gpumod-lti","type":"blocks","created_at":"2026-02-06T21:37:24.045109899+01:00","created_by":"Jaigouk Kim"},{"issue_id":"gpumod-vpv","depends_on_id":"gpumod-0gc","type":"blocks","created_at":"2026-02-06T21:44:08.509892415+01:00","created_by":"Jaigouk Kim"}]}
{"id":"gpumod-zl5","title":"Implement VRAMTracker","description":"## Goal\nImplement the VRAMTracker for monitoring GPU VRAM usage via nvidia-smi.\n\n## Problem\nBefore starting a service or switching modes, gpumod needs to know: how much VRAM is available? How much does each running process use? This requires parsing nvidia-smi output.\n\n## Architecture Reference\nRead docs/ARCHITECTURE.md before starting. Key principles:\n- VRAMTracker depends only on models.py (leaf-ish module)\n- All nvidia-smi calls are async via create_subprocess_exec\n- NvidiaSmiError raised when GPU tools unavailable\n- If you have a design question, update the ticket notes and tag ARCHITECT\n\n## Workflow: Red → Green → Refactor\n\n### RED: Write failing tests first\nCreate `tests/unit/test_vram.py`:\n- Mock `asyncio.create_subprocess_exec` for ALL tests (no real nvidia-smi)\n\nSample outputs to use in mocks:\n\nCSV (get_gpu_info): `\"NVIDIA GeForce RTX 4090, 24564, 560.35.03\\n\"`\nCSV (get_usage): `\"21700, 2864\\n\"`\nXML (get_process_vram):\n```xml\n\u003c?xml version=\"1.0\" ?\u003e\n\u003cnvidia_smi_log\u003e\n  \u003cgpu\u003e\n    \u003cprocesses\u003e\n      \u003cprocess_info\u003e\n        \u003cpid\u003e12345\u003c/pid\u003e\n        \u003cused_memory\u003e2500 MiB\u003c/used_memory\u003e\n      \u003c/process_info\u003e\n      \u003cprocess_info\u003e\n        \u003cpid\u003e67890\u003c/pid\u003e\n        \u003cused_memory\u003e19100 MiB\u003c/used_memory\u003e\n      \u003c/process_info\u003e\n    \u003c/processes\u003e\n  \u003c/gpu\u003e\n\u003c/nvidia_smi_log\u003e\n```\n\nTests:\n- Test get_gpu_info() parses CSV → GPUInfo(name=\"NVIDIA GeForce RTX 4090\", vram_total_mb=24564, driver=\"560.35.03\")\n- Test get_usage() parses CSV → VRAMUsage(used_mb=21700, free_mb=2864)\n- Test get_process_vram() parses XML → {12345: 2500, 67890: 19100}\n- Test get_process_vram() with no processes → empty dict\n- Test get_process_vram() with \"No running processes found\" text → empty dict\n- Test _run_nvidia_smi raises NvidiaSmiError on non-zero exit code\n- Test _run_nvidia_smi raises NvidiaSmiError when nvidia-smi not found (FileNotFoundError)\n- Test NvidiaSmiError message includes stderr content\n- Test estimate_service_vram returns service.vram_mb\n\nRun tests - they must ALL FAIL:\n```bash\nuv run pytest tests/unit/test_vram.py -v\n```\n\n### GREEN: Minimal implementation\nCreate `src/gpumod/services/vram.py` with VRAMTracker and NvidiaSmiError.\n\nRun tests - they must ALL PASS.\n\n### REFACTOR: Quality, Performance, Security\n1. **Code quality**: Robust CSV/XML parsing, clear error messages\n2. **Performance**: nvidia-smi calls are expensive (~100ms) - document caching opportunities for callers\n3. **Security**:\n   - No user input passed to nvidia-smi command (hardcoded args only)\n   - XML parsing: use defusedxml or verify ET.fromstring is safe for nvidia-smi output\n   - No shell=True in subprocess calls\n\n## Quality Gate (must pass before closing)\n```bash\nuv run ruff check src/gpumod/services/vram.py tests/unit/test_vram.py\nuv run mypy src/gpumod/services/vram.py --strict\nuv run pytest tests/unit/test_vram.py -v --cov=src/gpumod/services/vram --cov-report=term-missing --cov-fail-under=80\n```\nALL THREE must exit 0. Do not close this ticket until they do.\n\n## Acceptance Criteria\n- [ ] RED: All tests written and failing before implementation\n- [ ] GREEN: All tests passing with minimal implementation\n- [ ] REFACTOR: Code reviewed for quality, performance, security\n- [ ] get_gpu_info() returns GPUInfo from nvidia-smi CSV\n- [ ] get_usage() returns VRAMUsage from nvidia-smi CSV\n- [ ] get_process_vram() returns dict[int, int] from nvidia-smi XML\n- [ ] NvidiaSmiError raised when nvidia-smi missing or fails\n- [ ] All nvidia-smi calls are async\n- [ ] No user input in subprocess commands\n- [ ] `ruff check` passes\n- [ ] `mypy --strict` passes\n- [ ] Test coverage \u003e= 80%\n- [ ] Architecture compliant (checked against docs/ARCHITECTURE.md)","status":"open","priority":1,"issue_type":"task","owner":"ping@jaigouk.kim","created_at":"2026-02-06T21:37:03.088554764+01:00","created_by":"Jaigouk Kim","updated_at":"2026-02-06T21:47:38.329797227+01:00","dependencies":[{"issue_id":"gpumod-zl5","depends_on_id":"gpumod-kje","type":"blocks","created_at":"2026-02-06T21:37:24.487572183+01:00","created_by":"Jaigouk Kim"}]}
